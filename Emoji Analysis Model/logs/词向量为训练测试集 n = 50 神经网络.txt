D:\Users\Young\AppData\Local\Programs\Python\Python37\python.exe "D:\Program Files\JetBrains\PyCharm 2018.3.5\helpers\pydev\pydevconsole.py" --mode=client --port=64960
import sys; print('Python %s on %s' % (sys.version, sys.platform))
sys.path.extend(['E:\\大三下\\大作业\\数据挖掘\\Emoji Analysis Model', 'E:/大三下/大作业/数据挖掘/Emoji Analysis Model'])
PyDev console: starting.
Python 3.7.2 (tags/v3.7.2:9a3ffc0492, Dec 23 2018, 23:09:28) [MSC v.1916 64 bit (AMD64)] on win32
runfile('E:/大三下/大作业/数据挖掘/Emoji Analysis Model/neural_network.py', wdir='E:/大三下/大作业/数据挖掘/Emoji Analysis Model')
dsize= 50
models/sentence_vec_50d.npy
models/random_forest_third_tree_20_depth_2050.pickle
得到向量，开始训练：
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\utils\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.
  warnings.warn(msg, category=DeprecationWarning)
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\utils\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.
  warnings.warn(msg, category=DeprecationWarning)
round 0 --------------------
Running time: 5.140625 Seconds
Iteration 1, loss = 3.54165537
Iteration 2, loss = 3.50788762
Iteration 3, loss = 3.50044343
Iteration 4, loss = 3.49687259
Iteration 5, loss = 3.49521614
Iteration 6, loss = 3.49346367
Iteration 7, loss = 3.49209570
Iteration 8, loss = 3.49074453
Iteration 9, loss = 3.49031543
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
Iteration 10, loss = 3.48933888
score = 0.1525076172712212
round 1 --------------------
Running time: 127.203125 Seconds
Iteration 1, loss = 3.53970932
Iteration 2, loss = 3.50591786
Iteration 3, loss = 3.49882017
Iteration 4, loss = 3.49463558
Iteration 5, loss = 3.49235545
Iteration 6, loss = 3.49010183
Iteration 7, loss = 3.48869759
Iteration 8, loss = 3.48709726
Iteration 9, loss = 3.48632026
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
Iteration 10, loss = 3.48581630
score = 0.16018860711099783
round 2 --------------------
Running time: 250.5625 Seconds
Iteration 1, loss = 3.53951328
Iteration 2, loss = 3.50533556
Iteration 3, loss = 3.49793202
Iteration 4, loss = 3.49417755
Iteration 5, loss = 3.49155544
Iteration 6, loss = 3.48952556
Iteration 7, loss = 3.48758903
Iteration 8, loss = 3.48607344
Iteration 9, loss = 3.48503034
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
Iteration 10, loss = 3.48425838
score = 0.15086251839151035
round 3 --------------------
Running time: 376.671875 Seconds
Iteration 1, loss = 3.53843349
Iteration 2, loss = 3.50544116
Iteration 3, loss = 3.49706175
Iteration 4, loss = 3.49295790
Iteration 5, loss = 3.49022867
Iteration 6, loss = 3.48819680
Iteration 7, loss = 3.48717533
Iteration 8, loss = 3.48551314
Iteration 9, loss = 3.48486660
Iteration 10, loss = 3.48402304
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
score = 0.15109422245907528
round 4 --------------------
Running time: 499.25 Seconds
Iteration 1, loss = 3.54129088
Iteration 2, loss = 3.50812130
Iteration 3, loss = 3.50064853
Iteration 4, loss = 3.49639374
Iteration 5, loss = 3.49370724
Iteration 6, loss = 3.49167409
Iteration 7, loss = 3.49098279
Iteration 8, loss = 3.48960176
Iteration 9, loss = 3.48861254
Iteration 10, loss = 3.48785323
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
score = 0.15555632791139534
round 5 --------------------
Running time: 621.59375 Seconds
Iteration 1, loss = 3.53773545
Iteration 2, loss = 3.50333141
Iteration 3, loss = 3.49596096
Iteration 4, loss = 3.49226188
Iteration 5, loss = 3.48973291
Iteration 6, loss = 3.48795523
Iteration 7, loss = 3.48659430
Iteration 8, loss = 3.48509392
Iteration 9, loss = 3.48449332
Iteration 10, loss = 3.48326122
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
score = 0.14859354001575606
round 6 --------------------
Running time: 744.78125 Seconds
Iteration 1, loss = 3.53628732
Iteration 2, loss = 3.50399995
Iteration 3, loss = 3.49640578
Iteration 4, loss = 3.49181391
Iteration 5, loss = 3.48900833
Iteration 6, loss = 3.48699651
Iteration 7, loss = 3.48508976
Iteration 8, loss = 3.48356439
Iteration 9, loss = 3.48241621
Iteration 10, loss = 3.48194875
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
score = 0.14833866258862782
round 7 --------------------
Running time: 870.21875 Seconds
Iteration 1, loss = 3.54041776
Iteration 2, loss = 3.50671601
Iteration 3, loss = 3.49967076
Iteration 4, loss = 3.49594153
Iteration 5, loss = 3.49297144
Iteration 6, loss = 3.49112099
Iteration 7, loss = 3.48980020
Iteration 8, loss = 3.48890980
Iteration 9, loss = 3.48794474
Iteration 10, loss = 3.48670079
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
score = 0.1529843829649196
round 8 --------------------
Running time: 993.40625 Seconds
Iteration 1, loss = 3.53988867
Iteration 2, loss = 3.50517061
Iteration 3, loss = 3.49738315
Iteration 4, loss = 3.49329502
Iteration 5, loss = 3.49054826
Iteration 6, loss = 3.48950717
Iteration 7, loss = 3.48787000
Iteration 8, loss = 3.48715344
Iteration 9, loss = 3.48562155
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
Iteration 10, loss = 3.48513659
score = 0.14701793410259975
round 9 --------------------
Running time: 1118.046875 Seconds
Iteration 1, loss = 3.53866048
Iteration 2, loss = 3.50508748
Iteration 3, loss = 3.49634734
Iteration 4, loss = 3.49206321
Iteration 5, loss = 3.48951680
Iteration 6, loss = 3.48807439
Iteration 7, loss = 3.48686787
Iteration 8, loss = 3.48544257
Iteration 9, loss = 3.48567092
Iteration 10, loss = 3.48431810
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.
  % self.max_iter, ConvergenceWarning)
score = 0.15553315723620187
D:\Users\Young\AppData\Local\Programs\Python\Python37\lib\site-packages\sklearn\metrics\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
              precision    recall  f1-score   support
         0.0       0.00      0.00      0.00       542
         1.0       0.29      0.36      0.32      1282
         2.0       0.00      0.00      0.00       598
         3.0       0.20      0.65      0.30      6988
         4.0       0.00      0.00      0.00       223
         5.0       0.23      0.07      0.10       429
         6.0       0.30      0.02      0.04      1326
         7.0       0.10      0.04      0.05       250
         8.0       0.21      0.01      0.02       796
         9.0       0.00      0.00      0.00      1108
        10.0       0.00      0.00      0.00      1555
        11.0       0.00      0.00      0.00       641
        12.0       0.10      0.03      0.05      3597
        13.0       0.00      0.00      0.00       548
        14.0       0.15      0.22      0.18      4323
        15.0       0.07      0.00      0.00      2430
        16.0       0.69      0.02      0.03      2491
        17.0       0.05      0.00      0.01       750
        18.0       0.10      0.10      0.10      1005
        19.0       0.94      0.01      0.02      1391
        20.0       0.00      0.00      0.00       557
        21.0       0.10      0.01      0.01       409
        22.0       0.00      0.00      0.00       645
        23.0       0.00      0.00      0.00      3190
        24.0       0.00      0.00      0.00      1412
        25.0       0.00      0.00      0.00       327
        26.0       0.00      0.00      0.00       447
        27.0       0.00      0.00      0.00      1488
        28.0       0.00      0.00      0.00      1141
        29.0       0.08      0.42      0.14      4106
        30.0       0.12      0.05      0.07      1860
        31.0       0.09      0.06      0.07      3003
        32.0       0.00      0.00      0.00       811
        33.0       0.24      0.22      0.23       255
        34.0       0.10      0.10      0.10      4367
        35.0       0.18      0.52      0.26      6927
        36.0       0.00      0.00      0.00       697
        37.0       0.15      0.05      0.07       994
        38.0       0.21      0.10      0.13       606
        39.0       0.00      0.00      0.00       766
        40.0       0.00      0.00      0.00      1132
        41.0       0.00      0.00      0.00      1294
        42.0       0.17      0.26      0.21      1501
        43.0       0.20      0.02      0.04       465
        44.0       0.00      0.00      0.00       724
        45.0       0.00      0.00      0.00       698
        46.0       0.00      0.00      0.00       761
        47.0       0.00      0.00      0.00       483
        48.0       0.00      0.00      0.00       127
        49.0       0.00      0.00      0.00       458
        50.0       0.00      0.00      0.00      1095
        51.0       0.00      0.00      0.00       122
        52.0       0.09      0.00      0.01      2387
        53.0       0.00      0.00      0.00       228
        54.0       0.32      0.13      0.18       633
        55.0       0.00      0.00      0.00       501
        56.0       0.00      0.00      0.00       202
        57.0       0.00      0.00      0.00       353
        58.0       0.00      0.00      0.00      1021
        59.0       0.00      0.00      0.00       272
        60.0       0.00      0.00      0.00      1213
        61.0       0.00      0.00      0.00       523
        62.0       0.00      0.00      0.00      1087
        63.0       0.00      0.00      0.00       109
        64.0       0.00      0.00      0.00       400
        65.0       0.00      0.00      0.00        99
        66.0       0.00      0.00      0.00       183
        67.0       0.00      0.00      0.00       292
        68.0       0.00      0.00      0.00       774
        69.0       0.00      0.00      0.00       267
        70.0       0.00      0.00      0.00       354
        71.0       0.00      0.00      0.00       278
   micro avg       0.15      0.15      0.15     86317
   macro avg       0.08      0.05      0.04     86317
weighted avg       0.12      0.15      0.09     86317
scores
[0.1525076172712212, 0.16018860711099783, 0.15086251839151035, 0.15109422245907528, 0.15555632791139534, 0.14859354001575606, 0.14833866258862782, 0.1529843829649196, 0.14701793410259975, 0.15553315723620187]
models
[MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False), MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False)]
models[1]
MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(50, 50), learning_rate='constant',
       learning_rate_init=0.1, max_iter=10, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='sgd', tol=0.0001,
       validation_fraction=0.1, verbose=10, warm_start=False)
scores[1]
0.16018860711099783
scores[1]
0.16018860711099783
with open('models/neural_network'+str(d_size)+'.pickle', 'wb') as fp:
    pickle.dump(models[1], fp)
    
